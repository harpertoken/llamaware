server {
    listen 80;
    server_name localhost;

    location / {
        root /usr/share/nginx/html;
        index index.html;
        try_files $uri $uri/ =404;
    }

    # Mock Together AI API
    location /v1/chat/completions {
        return 200 '{
            "id": "mock-chat-completion",
            "object": "chat.completion",
            "created": 1677652288,
            "model": "meta-llama/Llama-2-70b-chat-hf",
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "This is a mock response from Together AI."
                },
                "finish_reason": "stop"
            }],
            "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 12,
                "total_tokens": 21
            }
        }';
        add_header Content-Type application/json;
    }
}